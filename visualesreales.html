<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Artimotion - Pro VJ Console</title>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Segoe UI', sans-serif; }
        
        #overlay { 
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: rgba(0,0,0,0.9); display: flex; flex-direction: column;
            justify-content: center; align-items: center; z-index: 20;
            transition: opacity 0.5s ease;
        }
        
        button#start-btn {
            padding: 15px 40px; font-size: 18px; color: #0ff; background: transparent;
            border: 2px solid #0ff; border-radius: 50px; cursor: pointer;
            box-shadow: 0 0 20px rgba(0,255,255,0.2); text-transform: uppercase; letter-spacing: 2px;
            margin: 10px; transition: all 0.3s;
        }
        button#start-btn:hover { background: #0ff; color: #000; box-shadow: 0 0 50px rgba(0,255,255,0.8); }

        #ui-container {
            position: absolute; bottom: 20px; left: 50%; transform: translateX(-50%);
            display: flex; gap: 15px; z-index: 10; align-items: center;
        }

        #file-input { display: none; }
        
        .action-btn {
            padding: 12px 25px; background: rgba(20, 20, 30, 0.9); 
            border: 1px solid #444; color: #fff; border-radius: 30px; 
            cursor: pointer; font-size: 12px; font-weight: bold; text-transform: uppercase;
            transition: 0.3s; display: flex; align-items: center; gap: 8px; min-width: 140px; justify-content: center;
        }
        .action-btn:hover { background: #333; border-color: #fff; box-shadow: 0 0 15px rgba(255,255,255,0.2); }
        
        /* Estados Activos */
        .action-btn.video-active { background: #ff0055; border-color: #ff0055; box-shadow: 0 0 20px #ff0055; color: white; }
        .action-btn.cam-active { background: #00ff66; border-color: #00ff66; box-shadow: 0 0 20px #00ff66; color: black; }

        .lil-gui { --background-color: rgba(10, 10, 10, 0.95); }
    </style>

    <script type="module">
        import * as THREE from 'https://cdn.skypack.dev/three@0.136.0';
        import { EffectComposer } from 'https://cdn.skypack.dev/three@0.136.0/examples/jsm/postprocessing/EffectComposer.js';
        import { RenderPass } from 'https://cdn.skypack.dev/three@0.136.0/examples/jsm/postprocessing/RenderPass.js';
        import { UnrealBloomPass } from 'https://cdn.skypack.dev/three@0.136.0/examples/jsm/postprocessing/UnrealBloomPass.js';
        import GUI from 'https://cdn.jsdelivr.net/npm/lil-gui@0.17.0/dist/lil-gui.esm.min.js';

        // --- PAR√ÅMETROS ---
        const params = {
            effectMode: 0, // 0:Glitch, 1:RGB, 2:Pixel, 3:Kaleido, 4:Holo, 5:Liquid
            mixRatio: 0.5,
            distortion: 2.0,     // Fuerza de deformaci√≥n 3D
            effectStrength: 1.0, // Intensidad del efecto visual
            bloomStrength: 1.5,
            wireframe: false,
            micGain: 5.0,
            speed: 1.0
        };

        const effectNames = {
            0: 'Standard Glitch',
            1: 'RGB Split',
            2: 'Pixelate',
            3: 'Kaleidoscope',
            4: 'Hologram',
            5: 'Liquid Warp'
        };

        // --- AUDIO ENGINE ---
        class AudioEngine {
            constructor() { this.ctx = null; this.analyser = null; this.data = null; this.freqData = null; this.isReady = false; }
            async init() {
                try {
                    this.ctx = new (window.AudioContext || window.webkitAudioContext)();
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: false, autoGainControl: false } });
                    this.analyser = this.ctx.createAnalyser();
                    this.analyser.fftSize = 512; 
                    const src = this.ctx.createMediaStreamSource(stream);
                    src.connect(this.analyser);
                    this.data = new Uint8Array(this.analyser.frequencyBinCount);
                    this.freqData = new Uint8Array(this.analyser.frequencyBinCount);
                    this.isReady = true;
                    return true;
                } catch(e) { console.error(e); return false; }
            }
            getLevels() {
                if(!this.isReady) return { vol: 0, bass: 0, mid: 0, high: 0 };
                this.analyser.getByteFrequencyData(this.freqData);
                this.analyser.getByteTimeDomainData(this.data);
                
                // Volumen general (RMS)
                let sum = 0; for(let i=0; i<this.data.length; i++) { const v=(this.data[i]-128)/128; sum+=v*v; }
                const vol = Math.sqrt(sum/this.data.length) * params.micGain;

                // Bandas de frecuencia (Simplificado)
                const bass = this.freqData[10] / 255.0;
                const mid = this.freqData[100] / 255.0;
                const high = this.freqData[200] / 255.0;

                return { vol, bass, mid, high };
            }
        }
        const audio = new AudioEngine();

        // --- SCENE SETUP ---
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
        camera.position.z = 8; // C√°mara un poco m√°s cerca
        const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // --- TEXTURAS & VIDEO ---
        const videoEl = document.createElement('video');
        videoEl.loop = true; videoEl.muted = true; videoEl.crossOrigin = "anonymous"; videoEl.playsInline = true;
        const videoTex = new THREE.VideoTexture(videoEl);

        const webcamEl = document.createElement('video');
        webcamEl.muted = true; webcamEl.playsInline = true;
        const webcamTex = new THREE.VideoTexture(webcamEl);

        function createPlasma() {
            const c=document.createElement('canvas'); c.width=64; c.height=64;
            const x=c.getContext('2d'); x.fillStyle='#000'; x.fillRect(0,0,64,64);
            return new THREE.CanvasTexture(c);
        }
        const placeholderTex = createPlasma();

        // --- SHADER PERSONALIZADO (VJ ENGINE) ---
        const uniforms = {
            uTexVideo: { value: placeholderTex },
            uTexCam: { value: placeholderTex },
            uMix: { value: 0.5 },
            uTime: { value: 0.0 },
            uHasVideo: { value: 0.0 },
            uHasCam: { value: 0.0 },
            uAudioVol: { value: 0.0 },  // Volumen General
            uAudioBass: { value: 0.0 }, // Bajos
            uAudioHigh: { value: 0.0 }, // Agudos
            uMode: { value: 0 },        // Modo de efecto
            uStrength: { value: 1.0 }   // Intensidad de efecto
        };

        const vertexShader = `
            uniform float uAudioVol;
            uniform float uAudioBass;
            uniform float uTime;
            uniform sampler2D uTexCam; 
            uniform sampler2D uTexVideo;
            uniform float uMix;
            uniform float uHasCam;

            varying vec2 vUv;
            varying float vElev;

            // Funci√≥n simple de ruido
            float random(vec2 st) { return fract(sin(dot(st.xy, vec2(12.9898,78.233))) * 43758.5453123); }
            float noise(vec2 st) {
                vec2 i = floor(st); vec2 f = fract(st);
                float a = random(i); float b = random(i + vec2(1.0, 0.0));
                float c = random(i + vec2(0.0, 1.0)); float d = random(i + vec2(1.0, 1.0));
                vec2 u = f * f * (3.0 - 2.0 * f);
                return mix(a, b, u.x) + (c - a)* u.y * (1.0 - u.x) + (d - b) * u.x * u.y;
            }

            void main() {
                vUv = uv;
                vec3 pos = position;

                // --- 1. DEFORMACI√ìN POR AUDIO (Ondas) ---
                float wave = sin(pos.x * 2.0 + uTime) * cos(pos.y * 1.5 + uTime);
                float glitch = wave * uAudioVol * 2.0;

                // --- 2. DEFORMACI√ìN POR IMAGEN (Profundidad) ---
                // Leemos el brillo de la c√°mara (si est√° activa) para "extruir" a la persona
                vec4 camColor = texture2D(uTexCam, uv);
                float brightness = length(camColor.rgb); // Simple luminancia
                
                // Si hay c√°mara, la deformaci√≥n responde a la silueta de la persona
                float extrusion = 0.0;
                if(uHasCam > 0.5) {
                    extrusion = brightness * uAudioBass * 3.0; // Los bajos empujan la silueta
                }

                pos.z += glitch + extrusion;
                vElev = pos.z; // Pasamos la altura al fragment para colorear si queremos

                gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
            }
        `;

        const fragmentShader = `
            uniform sampler2D uTexVideo;
            uniform sampler2D uTexCam;
            uniform float uMix;
            uniform float uTime;
            uniform float uHasVideo;
            uniform float uHasCam;
            uniform float uAudioVol;
            uniform float uAudioBass;
            uniform float uAudioHigh;
            uniform int uMode;
            uniform float uStrength;

            varying vec2 vUv;
            varying float vElev;

            // --- FUNCIONES DE EFECTOS --- //

            vec4 rgbSplit(sampler2D t, vec2 uv, float force) {
                vec2 dir = vec2(force * 0.02, 0.0);
                float r = texture2D(t, uv - dir).r;
                float g = texture2D(t, uv).g;
                float b = texture2D(t, uv + dir).b;
                return vec4(r, g, b, 1.0);
            }

            vec2 pixelate(vec2 uv, float pixels) {
                float dx = 15.0 * (1.0 / pixels);
                float dy = 10.0 * (1.0 / pixels);
                return vec2(dx * floor(uv.x / dx), dy * floor(uv.y / dy));
            }

            vec2 kaleidoscope(vec2 uv) {
                vec2 centered = uv - 0.5;
                float r = length(centered);
                float a = atan(centered.y, centered.x);
                float sides = 6.0;
                a = mod(a, 3.14159 * 2.0 / sides);
                a = abs(a - 3.14159 / sides);
                return 0.5 + r * vec2(cos(a), sin(a));
            }

            void main() {
                vec2 uv = vUv;
                
                // --- APLICAR EFECTOS A COORDENADAS UV ---
                
                // 2: Pixelate
                if (uMode == 2) {
                    float res = 50.0 + (1.0 - uAudioHigh) * 500.0; // Pixel size reacciona a agudos
                    uv = pixelate(uv, res);
                }
                // 3: Kaleidoscope
                if (uMode == 3) {
                    uv = kaleidoscope(uv);
                }
                // 5: Liquid
                if (uMode == 5) {
                    uv.x += sin(uv.y * 10.0 + uTime) * 0.05 * uAudioVol * uStrength;
                    uv.y += cos(uv.x * 10.0 + uTime) * 0.05 * uAudioVol * uStrength;
                }
                // 4: Hologram (Interferencia)
                float scanline = 1.0;
                if (uMode == 4) {
                    scanline = sin(uv.y * 800.0 + uTime * 10.0) * 0.5 + 0.5;
                    uv.x += sin(uv.y * 50.0 + uTime) * 0.01 * uAudioBass;
                }

                // --- OBTENER TEXTURAS BASE ---
                vec4 cVid = texture2D(uTexVideo, uv);
                vec4 cCam = texture2D(uTexCam, uv);

                // 1: RGB Split (se aplica al leer la textura)
                if (uMode == 1) {
                    if(uHasVideo > 0.5) cVid = rgbSplit(uTexVideo, uv, uAudioBass * uStrength);
                    if(uHasCam > 0.5) cCam = rgbSplit(uTexCam, uv, uAudioBass * uStrength);
                }

                // --- MEZCLA (MIXER) ---
                vec3 finalVid = (uHasVideo > 0.5) ? cVid.rgb : vec3(0.0);
                vec3 finalCam = (uHasCam > 0.5) ? cCam.rgb : vec3(0.0);

                // Si no hay nada, Plasma de fondo
                if (uHasVideo < 0.5 && uHasCam < 0.5) {
                    finalVid = 0.5 + 0.5 * cos(uTime + uv.xyx + vec3(0,2,4));
                }

                // L√≥gica de Mezcla (Video de fondo + C√°mara encima con modo Screen)
                vec3 color = mix(finalVid, finalCam, uMix);
                
                // Modo Screen artificial para resaltar a la banda
                if(uHasCam > 0.5 && uHasVideo > 0.5) {
                     color = finalVid + finalCam * uMix; // Additive mix for glow
                }

                // Aplicar Scanline del holograma
                if (uMode == 4) color *= (0.8 + 0.2 * scanline);

                gl_FragColor = vec4(color, 1.0);
            }
        `;

        const material = new THREE.ShaderMaterial({
            uniforms: uniforms,
            vertexShader: vertexShader,
            fragmentShader: fragmentShader,
            side: THREE.DoubleSide,
            wireframe: false
        });

        const geometry = new THREE.PlaneGeometry(16, 9, 120, 120); // Alta resoluci√≥n para buena deformaci√≥n
        const plane = new THREE.Mesh(geometry, material);
        scene.add(plane);

        // --- POST PROCESS ---
        const composer = new EffectComposer(renderer);
        composer.addPass(new RenderPass(scene, camera));
        const bloomPass = new UnrealBloomPass(new THREE.Vector2(window.innerWidth, window.innerHeight), 1.5, 0.4, 0.85);
        composer.addPass(bloomPass);

        // --- LOGIC ---
        function updatePlasma(time) {
            const tex = placeholderTex;
            const ctx = tex.image.getContext('2d');
            ctx.fillStyle = `hsl(${time*20 % 360}, 50%, 20%)`; 
            ctx.fillRect(0,0,64,64); // Fondo oscuro
            ctx.fillStyle = '#fff';
            if(Math.random()>0.9) ctx.fillRect(Math.random()*64, Math.random()*64, 2, 2); // Estrellas
            tex.needsUpdate = true;
        }

        function animate() {
            requestAnimationFrame(animate);
            const time = performance.now() * 0.001 * params.speed;
            const audioData = audio.getLevels();

            // Update Uniforms
            uniforms.uTime.value = time;
            uniforms.uMix.value = params.mixRatio;
            uniforms.uMode.value = params.effectMode;
            uniforms.uStrength.value = params.effectStrength;

            // Audio Uniforms
            uniforms.uAudioVol.value = audioData.vol;
            uniforms.uAudioBass.value = audioData.bass;
            uniforms.uAudioHigh.value = audioData.high;

            // Plasma fallback
            if(uniforms.uHasVideo.value === 0 && uniforms.uHasCam.value === 0) updatePlasma(time);

            // Reactivity
            bloomPass.strength = params.bloomStrength + (audioData.vol * 1.5);
            material.wireframe = params.wireframe;

            // Camera Motion
            if(audioData.bass > 0.6) {
                plane.rotation.z = (Math.random()-0.5) * 0.02 * params.distortion;
                plane.scale.setScalar(1.0 + audioData.bass * 0.05);
            } else {
                plane.rotation.z *= 0.9;
                plane.scale.lerp(new THREE.Vector3(1,1,1), 0.1);
            }

            composer.render();
        }

        // --- MANEJO DE ESTADOS (TOGGLE) ---
        let isVideoActive = false;
        let isCamActive = false;

        // 1. Start Audio
        document.getElementById('start-btn').onclick = async () => {
            if(await audio.init()) {
                document.getElementById('overlay').style.opacity = 0;
                setTimeout(()=>document.getElementById('overlay').style.display='none', 500);
                animate();
            }
        };

        // 2. Video Toggle
        const btnLoad = document.getElementById('btn-load-video');
        const fileInput = document.getElementById('file-input');

        btnLoad.onclick = () => {
            if(isVideoActive) {
                // APAGAR VIDEO
                videoEl.pause();
                uniforms.uHasVideo.value = 0.0;
                isVideoActive = false;
                btnLoad.classList.remove('video-active');
                btnLoad.innerHTML = "üìÇ CARGAR VIDEO";
            } else {
                // ENCENDER VIDEO
                if(!videoEl.src) {
                    fileInput.click(); // Primer carga
                } else {
                    videoEl.play();
                    uniforms.uHasVideo.value = 1.0;
                    isVideoActive = true;
                    btnLoad.classList.add('video-active');
                    btnLoad.innerHTML = "‚èπ DETENER VIDEO";
                }
            }
        };

        fileInput.onchange = (e) => {
            const file = e.target.files[0];
            if(!file) return;
            const url = URL.createObjectURL(file);
            videoEl.src = url;
            videoEl.play().then(() => {
                uniforms.uTexVideo.value = videoTex;
                uniforms.uHasVideo.value = 1.0;
                isVideoActive = true;
                btnLoad.classList.add('video-active');
                btnLoad.innerHTML = "‚èπ DETENER VIDEO";
            });
        };

        // 3. Cam Toggle
        const btnCam = document.getElementById('btn-cam');
        let camStream = null;

        btnCam.onclick = async () => {
            if(isCamActive) {
                // APAGAR CAMARA
                if(camStream) {
                    const tracks = camStream.getTracks();
                    tracks.forEach(track => track.stop());
                }
                webcamEl.srcObject = null;
                uniforms.uHasCam.value = 0.0;
                isCamActive = false;
                btnCam.classList.remove('cam-active');
                btnCam.innerHTML = "üì∑ ACTIVAR C√ÅMARA";
            } else {
                // ENCENDER CAMARA
                try {
                    camStream = await navigator.mediaDevices.getUserMedia({ video: { width: 1280, height: 720 } });
                    webcamEl.srcObject = camStream;
                    webcamEl.play().then(() => {
                        uniforms.uTexCam.value = webcamTex;
                        uniforms.uHasCam.value = 1.0;
                        isCamActive = true;
                        btnCam.classList.add('cam-active');
                        btnCam.innerHTML = "üö´ APAGAR C√ÅMARA";
                        // Auto-ajustar mezcla para que se note
                        if(isVideoActive) params.mixRatio = 0.5;
                        else params.mixRatio = 1.0;
                    });
                } catch(err) {
                    console.error(err);
                    alert("Error al acceder a la c√°mara");
                }
            }
        };

        window.onresize = () => {
            camera.aspect = window.innerWidth/window.innerHeight; camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight); composer.setSize(window.innerWidth, window.innerHeight);
        };

        // --- GUI ---
        const gui = new GUI({ title: 'VJ CONSOLE' });
        
        const fMix = gui.addFolder('Mezcla & Fuente');
        fMix.add(params, 'mixRatio', 0.0, 1.0).name('Crossfader Vid/Cam').listen();
        
        const fEffects = gui.addFolder('Efectos Visuales');
        fEffects.add(params, 'effectMode', effectNames).name('MODO FX').onChange(v => {
            // Convert string back to int key if needed by dat.gui quirks
            params.effectMode = parseInt(Object.keys(effectNames).find(key => effectNames[key] === v));
        });
        fEffects.add(params, 'effectStrength', 0.0, 2.0).name('Intensidad FX');
        fEffects.add(params, 'distortion', 0.0, 5.0).name('Deformaci√≥n 3D');
        fEffects.add(params, 'wireframe').name('Modo Malla');
        fEffects.add(params, 'bloomStrength', 0.0, 3.0).name('Brillo Ne√≥n');

        const fAudio = gui.addFolder('Audio');
        fAudio.add(params, 'micGain', 1.0, 10.0).name('Sensibilidad Mic');

    </script>
</head>
<body>
    <div id="overlay">
        <h1 style="color:white; letter-spacing: 5px; text-transform:uppercase;">Artimotion VJ Console</h1>
        <button id="start-btn">INICIAR SISTEMA</button>
    </div>

    <div id="ui-container">
        <input type="file" id="file-input" accept="video/*">
        
        <div id="btn-load-video" class="action-btn">üìÇ Cargar Video</div>
        <div id="btn-cam" class="action-btn">üì∑ Activar C√°mara</div>
    </div>
</body>
</html>
