<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>ALEX V.3.0 CORE</title>
    <link href="https://fonts.googleapis.com/css2?family=Rajdhani:wght@600;700&display=swap" rel="stylesheet">
    
    <style>
        body { 
            margin: 0; overflow: hidden; background: #000; 
            font-family: 'Rajdhani', sans-serif; color: #fff; 
        }
        #ui {
            position: absolute; top: 20px; left: 20px; z-index: 10;
            pointer-events: none;
        }
        h1 { margin: 0; font-size: 24px; color: #FF3300; letter-spacing: 2px; }
        p { font-size: 14px; color: #888; margin-top: 5px; }
        .key { color: #fff; font-weight: bold; background: #333; padding: 2px 6px; border-radius: 4px; }
        
        #hidden-inputs { display: none; }
        
        #status-bar {
            position: absolute; bottom: 20px; left: 20px;
            font-family: monospace; font-size: 12px; color: #666;
        }
    </style>
    <!-- THREE.JS CDN -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js"
            }
        }
    </script>
</head>
<body>

    <div id="ui">
        <h1>ALEX V.3 CORE</h1>
        <p><span class="key">A</span> - <span class="key">L</span> : Cargar / Disparar Clips</p>
        <p><span class="key">Q</span> : TRANSFORMACIÓN 3D (Toggle)</p>
        <p><span class="key">M</span> : Resetear</p>
        <p style="color: #FF3300; margin-top: 10px;">* Haz click en la pantalla para activar el audio *</p>
    </div>

    <div id="status-bar">ESPERANDO CLIP...</div>
    <div id="hidden-inputs">
        <input type="file" id="file-input" accept="video/*">
        <input type="file" id="audio-input" accept="audio/*">
    </div>

    <script type="module">
        import * as THREE from 'three';

        // --- CONFIGURACIÓN ---
        let scene, camera, renderer;
        let screenMesh;
        let uniforms;
        let audioCtx, analyser, dataArray;
        let is3DMode = false;
        let morphValue = 0.0; // 0 = Plano, 1 = Esfera
        
        // Bancos de video
        const videoBank = {};
        let pendingKey = null;
        let currentVideo = null; // Elemento de video HTML actual

        // Variables de audio
        const audioData = { bass: 0, mid: 0, high: 0, vol: 0 };

        init();
        animate();

        function init() {
            // 1. ESCENA
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x000000);

            camera = new THREE.PerspectiveCamera(60, window.innerWidth / window.innerHeight, 0.1, 100);
            camera.position.z = 8; // Distancia perfecta para llenar pantalla en 16:9

            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // 2. MATERIAL Y GEOMETRÍA
            // Usamos un plano con MUCHOS segmentos para poder doblarlo
            const geometry = new THREE.PlaneGeometry(16, 9, 200, 112); 

            // Textura inicial (negro)
            const placeholder = createPlaceholderTexture();

            uniforms = {
                uTex: { value: placeholder },
                uTime: { value: 0 },
                uMorph: { value: 0.0 }, // Controla la transición 2D -> 3D
                uBass: { value: 0.0 },
                uMid: { value: 0.0 },
                uHigh: { value: 0.0 }
            };

            // --- SHADERS SIMPLIFICADOS ---
            
            const vertexShader = `
                uniform float uTime;
                uniform float uMorph; // 0.0 a 1.0
                uniform float uBass;
                uniform float uMid;
                uniform float uHigh;
                
                varying vec2 vUv;
                varying float vDisplacement; // Para sombrear según deformación

                // Ruido simple
                vec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
                vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
                vec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); }
                vec4 taylorInvSqrt(vec4 r) { return 1.79284291400159 - 0.85373472095314 * r; }
                float snoise(vec3 v) {
                    const vec2  C = vec2(1.0/6.0, 1.0/3.0) ;
                    const vec4  D = vec4(0.0, 0.5, 1.0, 2.0);
                    vec3 i  = floor(v + dot(v, C.yyy) );
                    vec3 x0 = v - i + dot(i, C.xxx) ;
                    vec3 g = step(x0.yzx, x0.xyz);
                    vec3 l = 1.0 - g;
                    vec3 i1 = min( g.xyz, l.zxy );
                    vec3 i2 = max( g.xyz, l.zxy );
                    vec3 x1 = x0 - i1 + C.xxx;
                    vec3 x2 = x0 - i2 + C.yyy;
                    vec3 x3 = x0 - D.yyy;
                    i = mod289(i);
                    vec4 p = permute( permute( permute(
                            i.z + vec4(0.0, i1.z, i2.z, 1.0 ))
                            + i.y + vec4(0.0, i1.y, i2.y, 1.0 ))
                            + i.x + vec4(0.0, i1.x, i2.x, 1.0 ));
                    float n_ = 0.142857142857;
                    vec3  ns = n_ * D.wyz - D.xzx;
                    vec4 j = p - 49.0 * floor(p * ns.z * ns.z);
                    vec4 x_ = floor(j * ns.z);
                    vec4 y_ = floor(j - 7.0 * x_ );
                    vec4 x = x_ *ns.x + ns.yyyy;
                    vec4 y = y_ *ns.x + ns.yyyy;
                    vec4 h = 1.0 - abs(x) - abs(y);
                    vec4 b0 = vec4( x.xy, y.xy );
                    vec4 b1 = vec4( x.zw, y.zw );
                    vec4 s0 = floor(b0)*2.0 + 1.0;
                    vec4 s1 = floor(b1)*2.0 + 1.0;
                    vec4 sh = -step(h, vec4(0.0));
                    vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ;
                    vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ;
                    vec3 p0 = vec3(a0.xy,h.x);
                    vec3 p1 = vec3(a0.zw,h.y);
                    vec3 p2 = vec3(a1.xy,h.z);
                    vec3 p3 = vec3(a1.zw,h.w);
                    vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));
                    p0 *= norm.x;
                    p1 *= norm.y;
                    p2 *= norm.z;
                    p3 *= norm.w;
                    vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);
                    m = m * m;
                    return 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3) ) );
                }

                void main() {
                    vUv = uv;
                    
                    // --- GEOMETRÍA PLANA (VIDEO NORMAL) ---
                    vec3 pos2D = position;
                    // Reactividad 2D: Leve escala con el bajo
                    pos2D.z += sin(length(pos2D) * 2.0 - uTime) * 0.1 * uBass;

                    // --- GEOMETRÍA 3D (ESFERA ENROLLADA) ---
                    // Mapeamos el plano rectangular a coordenadas esféricas
                    float radius = 3.5;
                    float phi = (uv.x - 0.5) * 3.14159 * 2.0; // Longitud
                    float theta = (uv.y - 0.5) * 3.14159;     // Latitud
                    
                    vec3 pos3D;
                    pos3D.x = radius * cos(theta) * sin(phi);
                    pos3D.y = radius * sin(theta);
                    pos3D.z = radius * cos(theta) * cos(phi);

                    // Deformación Orgánica 3D
                    float noiseVal = snoise(pos3D * 0.5 + uTime * 0.5);
                    float spike = uBass * 1.5 + uMid * 0.5; // El audio empuja los vértices
                    pos3D += normalize(pos3D) * (noiseVal * spike);
                    
                    vDisplacement = noiseVal * spike; // Pasamos esto al fragment para las sombras

                    // --- MEZCLA (TRANSICIÓN SUAVE) ---
                    vec3 finalPos = mix(pos2D, pos3D, uMorph);

                    gl_Position = projectionMatrix * modelViewMatrix * vec4(finalPos, 1.0);
                }
            `;

            const fragmentShader = `
                uniform sampler2D uTex;
                uniform float uMorph;
                varying vec2 vUv;
                varying float vDisplacement;

                void main() {
                    // Muestreamos el color EXACTO del video
                    vec4 texColor = texture2D(uTex, vUv);
                    
                    // --- SIN LUZ BLANCA ESPECULAR ---
                    // En lugar de añadir blanco, OSCURECEMOS los valles de la deformación
                    // para crear volumen sin lavar los colores.
                    
                    float shadow = 1.0;
                    
                    // Solo aplicamos sombras en modo 3D
                    if(uMorph > 0.1) {
                        // Si el desplazamiento es negativo (valle), oscurecemos
                        shadow = smoothstep(-0.5, 0.8, vDisplacement + 0.2);
                        // Aseguramos que no sea negro total
                        shadow = clamp(shadow, 0.3, 1.0); 
                    }

                    vec3 finalColor = texColor.rgb * shadow;

                    gl_FragColor = vec4(finalColor, 1.0);
                }
            `;

            const material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: vertexShader,
                fragmentShader: fragmentShader,
                side: THREE.DoubleSide // Importante para ver el "interior" al doblarse
            });

            screenMesh = new THREE.Mesh(geometry, material);
            scene.add(screenMesh);

            // 3. LISTENERS
            window.addEventListener('resize', onWindowResize);
            window.addEventListener('keydown', onKeyDown);
            window.addEventListener('click', initAudioContext); // Click para audio
            
            // Input handlers
            document.getElementById('file-input').addEventListener('change', handleFileSelect);
        }

        // --- LÓGICA DE VIDEO ---
        function createPlaceholderTexture() {
            const canvas = document.createElement('canvas');
            canvas.width = 1280; canvas.height = 720;
            const ctx = canvas.getContext('2d');
            ctx.fillStyle = '#111'; ctx.fillRect(0,0,1280,720);
            ctx.fillStyle = '#333'; ctx.font = "bold 100px Arial"; ctx.textAlign = "center";
            ctx.fillText("NO SIGNAL", 640, 360);
            return new THREE.CanvasTexture(canvas);
        }

        function loadVideo(file, key) {
            const url = URL.createObjectURL(file);
            const video = document.createElement('video');
            video.src = url;
            video.loop = true;
            video.muted = true;
            video.play();
            
            const tex = new THREE.VideoTexture(video);
            tex.minFilter = THREE.LinearFilter;
            tex.magFilter = THREE.LinearFilter;
            
            videoBank[key] = { video: video, texture: tex, name: file.name };
            playClip(key);
        }

        function playClip(key) {
            if(!videoBank[key]) return;
            
            // Pausar anterior si existe
            if(currentVideo) currentVideo.pause();
            
            const clip = videoBank[key];
            currentVideo = clip.video;
            currentVideo.play();
            
            uniforms.uTex.value = clip.texture;
            document.getElementById('status-bar').innerText = `REPRODUCIENDO: [${key}] ${clip.name}`;
        }

        function handleFileSelect(e) {
            if(e.target.files.length > 0 && pendingKey) {
                loadVideo(e.target.files[0], pendingKey);
                pendingKey = null;
            }
            e.target.value = ''; // Reset
        }

        // --- INPUTS ---
        function onKeyDown(e) {
            const k = e.key.toLowerCase();
            const keys = ['a','s','d','f','g','h','j','k','l'];

            // Cargar / Disparar Clips
            if (keys.includes(k)) {
                if (videoBank[k]) {
                    playClip(k);
                } else {
                    pendingKey = k;
                    document.getElementById('file-input').click();
                }
            }

            // Transformación (Q) - Toggle simple
            if (k === 'q') {
                is3DMode = !is3DMode;
                document.getElementById('status-bar').innerText = is3DMode ? "MODO: 3D (AUDIO REACTIVO)" : "MODO: 2D (VIDEO PLANO)";
            }

            // Reset
            if (k === 'm') {
                is3DMode = false;
                morphValue = 0;
            }
        }

        // --- AUDIO ---
        async function initAudioContext() {
            if(audioCtx) return;
            try {
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 512;
                dataArray = new Uint8Array(analyser.frequencyBinCount);

                // Capturar micrófono / loopback
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const source = audioCtx.createMediaStreamSource(stream);
                source.connect(analyser);
                
                document.querySelector('#ui p:last-child').style.display = 'none'; // Ocultar aviso
                console.log("Audio iniciado");
            } catch(e) {
                console.error("Error audio", e);
            }
        }

        function analyzeAudio() {
            if(!analyser) return;
            analyser.getByteFrequencyData(dataArray);
            
            // Promediar bandas (simplificado)
            let b = 0, m = 0, h = 0;
            for(let i=0; i<10; i++) b += dataArray[i];
            for(let i=10; i<100; i++) m += dataArray[i];
            for(let i=100; i<200; i++) h += dataArray[i];

            // Suavizado (Lerp) para que no parpadee
            audioData.bass += ((b / 10 / 255.0) - audioData.bass) * 0.2;
            audioData.mid += ((m / 90 / 255.0) - audioData.mid) * 0.2;
            audioData.high += ((h / 100 / 255.0) - audioData.high) * 0.2;
        }

        // --- BUCLE ---
        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function animate() {
            requestAnimationFrame(animate);
            analyzeAudio();

            uniforms.uTime.value += 0.01;
            
            // Pasar datos de audio al shader
            // Multiplicamos por sensibilidad
            uniforms.uBass.value = audioData.bass;
            uniforms.uMid.value = audioData.mid;
            uniforms.uHigh.value = audioData.high;

            // Interpolación suave del modo 3D
            const targetMorph = is3DMode ? 1.0 : 0.0;
            morphValue += (targetMorph - morphValue) * 0.05; // Transición lenta y elegante
            uniforms.uMorph.value = morphValue;

            // Rotación sutil de la cámara o el objeto en modo 3D para darle dinamismo
            if (morphValue > 0.1) {
                screenMesh.rotation.y += 0.002;
            } else {
                // En 2D volvemos lentamente a rotación 0
                screenMesh.rotation.y *= 0.9;
                screenMesh.rotation.x *= 0.9;
            }

            renderer.render(scene, camera);
        }
    </script>
</body>
</html>
